{"cells":[{"cell_type":"code","source":["# Run this cell to setup data path\nimport os\n\ndataPath = os.getcwd()\nif dataPath.find('databricks') != -1:\n    ACCESS_KEY = \"AKIAIDY2HFQQR3YOOPJA\"\n    SECRET_KEY = \"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\"\n    AWS_BUCKET_NAME = \"beerproject\"\n    dataPath = \"s3a://%s:%s@%s/\" %(ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["ratingPath = os.path.join(dataPath, \"scraped_data/beer_ratings_only.csv\")\ntextRDD = sc.textFile(ratingPath)\ntextRDD.take(5)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nratingSchema = StructType([StructField(\"user_name\", StringType(), True),\n                           StructField(\"overall\", StringType(), True),\n                           StructField(\"beer_name\", StringType(), True)])\n\nratingPath = os.path.join(dataPath, \"scraped_data/beer_ratings_only.csv\")\nratings = spark.read.option(\"header\",\"true\").csv(path=ratingPath, sep=\",\", schema=ratingSchema)\nratings = ratings.withColumn(\"overall\", ratings.overall.cast(\"integer\")).dropna(how='any')\n\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\n\nindexer1 = StringIndexer(inputCol=\"user_name\", outputCol=\"usernameIndex\")\nindexer2 = StringIndexer(inputCol=\"beer_name\", outputCol=\"beernameIndex\")\nratings_indexed1 = indexer1.fit(ratings).transform(ratings)\nratings_indexed = indexer2.fit(ratings_indexed1).transform(ratings_indexed1)\nratings_indexed.show(5)\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\ntraining, test = ratings_indexed.randomSplit([0.8, 0.2])\n\nals = ALS(maxIter=100, regParam=0.01, \n          userCol=\"usernameIndex\", itemCol=\"beernameIndex\", ratingCol=\"overall\")\n\nmodel = als.fit(training)\n\n# Evaluate the model by computing the RMSE on the test data\npredictions = model.transform(test).dropna(how='any')\n\nevaluator = RegressionEvaluator(metricName=\"rmse\", \n                                labelCol=\"overall\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint \"RMSE = \" + str(rmse)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(als.regParam, [0.03, 0.1, 0.3])\n             .addGrid(als.maxIter, [50, 75, 100])\n             .addGrid(als.rank, [15, 20, 25])\n             .build())\n\ncrossval = CrossValidator(estimator=als,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=RegressionEvaluator(metricName=\"rmse\", \n                                                        labelCol=\"overall\",\n                                                        predictionCol=\"prediction\"),\n                          numFolds=5)  # use 3+ folds in practice\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\n\n# Make predictions on test documents. cvModel uses the best model found (lrModel).\nprediction = cvModel.transform(test).dropna(how='any')\nevaluator = RegressionEvaluator(metricName=\"rmse\", \n                                labelCol=\"overall\",\n                                predictionCol=\"prediction\")\nrmse = evaluator.evaluate(predictions)\nprint \"RMSE = \" + str(rmse)"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"ALS_Beer_Rec","notebookId":3994082152925320},"nbformat":4,"nbformat_minor":0}
